{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Model Building\n",
    "\n",
    "Here you try your hand at model building to predict appointment no shows.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Package 'proj2_lib' now includes code to carry out preprocessing steps from part I. Here's how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noshow_lib.util as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it includes a dictionary used for configuring path and file names\n",
    "used through the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_data_path': 'C:/Vidit/PhD/Fall 2018/CMSC 643 - Hector/Project 2/cmsc643_noshow-master/part2_data/data',\n",
       " 'raw_data_csv': 'KaggleV2-May-2016.csv',\n",
       " 'processed_data_path': 'C:/Vidit/PhD/Fall 2018/CMSC 643 - Hector/Project 2/cmsc643_noshow-master/part2_data/processed_dir',\n",
       " 'train_csv': 'train_set.csv',\n",
       " 'test_csv': 'test_set.csv',\n",
       " 'objstore_path': 'C:/Vidit/PhD/Fall 2018/CMSC 643 - Hector/Project 2/cmsc643_noshow-master/part2_data/objects',\n",
       " 'feature_pipeline_file': 'feature_pipeline.pkl',\n",
       " 'labels_pipeline_file': 'labels_pipeline.pkl'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.file_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature_pipeline_file`: file storing the preprocessing pipeline used for preparing the feature matrix\n",
    "\n",
    "`labels_pipeline_file`: file storing the preprocessing pipeline used for\n",
    "preparing labels\n",
    "\n",
    "`objstore_path`: directory to store python objects to disk\n",
    "\n",
    "`processed_data_path`: directory containing processed data\n",
    "\n",
    "`raw_data_csv`: name of the csv download from Kaggle\n",
    "\n",
    "`raw_data_path`: directory containing raw data\n",
    "\n",
    "`test_csv`: name of csv file containing test set\n",
    "\n",
    "`train_csv`: name of csv file containing train set\n",
    "\n",
    "You can change these paths and names to suit your project directory structure if you need so. E.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config = utils.file_config\n",
    "#config['raw_data_path'] = \"some_other_directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create train test sets. Code is in file `noshow_lib/util.py` function `make_train_test_sets`. You\n",
    "can edit that function as needed to include your own part I code if you so desire. The result will be to \n",
    "create files `train_set.csv` and `test_set.csv` in your `processed_data` directory (unless you change any of the entries in the configuration directory as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY NEED TO RUN THIS STEP ONCE (switch this to True to run it)\n",
    "RUN_MAKE_TRAIN_TEST_FILES = True\n",
    "if RUN_MAKE_TRAIN_TEST_FILES:\n",
    "    utils.make_train_test_sets(config=file_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to fit the preprocessing pipelines. This is done in file `noshow_lib/preprocess.py`. Again you can edit code as needed in that file to incorporate your part I solution as you wish. The result will be to create files `feature_pipeline.pkl` and `labels_pipeline.pkl` containing the fit preprocessing pipelines we can then use to preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noshow_lib.preprocess as preprocess\n",
    "\n",
    "# ONLY NEED TO RUN THIS STEP ONCE\n",
    "RUN_FIT_PREPROCESSING = False\n",
    "if RUN_FIT_PREPROCESSING:\n",
    "    preprocess.fit_save_pipelines(config=file_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once we do that, we can get a training matrix and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = preprocess.load_train_data(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90526, 101)\n",
      "(90526,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "Using `sklearn` fit:\n",
    "    - DecisionTree classifier\n",
    "    - RandomForest classifier\n",
    "    - Linear SVM classifier\n",
    "    - SVM with Radial Basis Kernel classifier\n",
    "    \n",
    "Use default parameters for now.\n",
    "Using 10-fold cross validation report both accuracy and AUC for each of the above four models.\n",
    "\n",
    "QUESTION: Should you use accuracy or AUC for this task as a performance metric?\n",
    "\n",
    "_Since the class distribution is skewed it is better to use AUC as a measure of performance_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build your models here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_classifier, train_X, train_y, \n",
    "                         scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7378542592429255"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy of Decision Tree classifier\n",
    "import numpy as np\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores = cross_val_score(tree_classifier, train_X, train_y,\n",
    "                            scoring='roc_auc', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5841021944701812"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean AUC score of Decision Tree classifier\n",
    "np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_accuracy = cross_val_score(rf_classifier, train_X, train_y, \n",
    "                             scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7788259253859252"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy of Random Forest classifier\n",
    "np.mean(rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_auc = cross_val_score(rf_classifier, train_X, train_y, \n",
    "                        scoring='roc_auc', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6906707278750058"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean AUC of RF classifier\n",
    "np.mean(rf_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svm = LinearSVC(dual=False)\n",
    "lsvm_accuracy = cross_val_score(linear_svm, train_X, train_y,\n",
    "                               scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962463938609863"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy of linear SVM\n",
    "np.mean(lsvm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvm_auc = cross_val_score(linear_svm, train_X, train_y,\n",
    "                          scoring='roc_auc', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.667329796667954"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean AUC of linear SVM\n",
    "np.mean(lsvm_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not running this to save some time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rbf_svm = SVC(kernel='rbf', gamma='auto')\n",
    "#rbf_accuracy = cross_val_score(rbf_svm, train_X, train_y,\n",
    "#                             scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean accuracy of non-linear SVM\n",
    "#np.mean(rbf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rbf_auc = cross_val_score(rbf_svm, train_X, train_y,\n",
    "#                         scoring='roc_auc', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean AUC of non-linear SVM\n",
    "#np.mean(rbf_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning\n",
    "\n",
    "Based on the above, choose two methods and fit a tuned model:\n",
    "    - use 5-fold cross validation for model selection\n",
    "    - use 10-fold cross validation for model assessment (based on appropriate performance metric)\n",
    "\n",
    "Report estimated performance for both tuned classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune your models here\n",
    "# using Random Forest and Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 5, 10, 20]}\n",
    "]\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_tuner = GridSearchCV(rf_classifier, rf_param_grid, cv=5,\n",
    "                        scoring='roc_auc', n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rf_auc = cross_val_score(rf_tuner, train_X, train_y,\n",
    "                              scoring='roc_auc', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7153227530349607"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean tuned random forest AUC\n",
    "np.mean(tuned_rf_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_param_grid = [\n",
    "    {'C': 2 ** np.linspace(-3, 5, num=5)}\n",
    "]\n",
    "\n",
    "svm_classifier = LinearSVC()\n",
    "svm_tuner = GridSearchCV(svm_classifier, svm_param_grid, cv=5,\n",
    "                        scoring='roc_auc', n_jobs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    }
   ],
   "source": [
    "tuned_svm_auc = cross_val_score(svm_tuner, train_X, train_y,\n",
    "                               scoring='roc_auc', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6683920205870576"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tuned_svm_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# initialize model parameters w and b\n",
    "# intializing to 0 is not a good idea\n",
    "# it should be a random vector see np.random.randn\n",
    "# YOU NEED TO IMPLEMENT THIS\n",
    "def _initialize_parameters(nfeatures):\n",
    "    sd = math.sqrt( 0.5 * nfeatures)\n",
    "    w = np.random.randn(nfeatures) / sd \n",
    "    b = np.random.randn(1) / sd\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the signed distances for observations $X$, given weights $w$ and offset (bias) $b$\n",
    "\n",
    "$$\n",
    "f = Xw + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the signed distances\n",
    "# based on current model estimates\n",
    "# w and b\n",
    "# YOU NEED TO IMPLEMENT THIS\n",
    "def _get_signed_distances(X, w, b):\n",
    "    f = np.dot(X, w) + b\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective function for linear SVM\n",
    "\n",
    "$$\n",
    "L(w,b) = \\frac{1}{n} \\sum_{i=1}^n (1-y_i f_i)_+ + \\frac{\\lambda}{2} \\| w \\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a vectorized version of positive_part operation\n",
    "# we can use this for hinge loss as post_part(1.0 - y*f)\n",
    "pos_part = np.vectorize(lambda u: u if u > 0. else 0.)\n",
    "\n",
    "# compute the value of the linear SVM objective function\n",
    "# given current signed distances, and parameter vector w\n",
    "def _get_objective(f, y, w, lam):\n",
    "    nobs = y.shape[0]\n",
    "    loss = np.sum(pos_part(1.0 - y*f)) / nobs\n",
    "    penalty = 0.5 * lam * np.dot(w,w)\n",
    "    return loss + penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients of the objective function\n",
    "\n",
    "$$\n",
    "\\nabla_w L = \\frac{1}{n} \\sum_{i=1}^n t_i y_i x_i + \\lambda w\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^n t_i y_i\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "t_i =\n",
    "\\begin{cases}\n",
    "1 & \\mathrm{if} \\; 1-y_if_i > 0 \\\\\n",
    "0 & \\mathrm{o.w.}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradients with respect to w and b\n",
    "# YOU NEEED TO IMPLEMENT THIS\n",
    "subgrad = np.vectorize(lambda r: 1. if  r > 0. else 0.)\n",
    "\n",
    "def _get_gradients(f, X, y, w, b, lam):\n",
    "    nobs = X.shape[0]\n",
    "    yf = y * f\n",
    "    t = subgrad(1. - yf)\n",
    "    ty = t * y\n",
    "    \n",
    "    gw = np.sum(np.multiply(X.T, ty).T, axis=0) / nobs\n",
    "    gw += lam * w\n",
    "    gb = np.sum(ty) / nobs\n",
    "    return gw, gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an SVM using gradient descent\n",
    "# X: matrix of feature values\n",
    "# y: labels (-1 or 1)\n",
    "# n_iter: numer of iterations\n",
    "# eta: learning rate\n",
    "# tol: if the norm of the gradient becomes less than this, stop iterations\n",
    "# verbose: print iteration information if > 0\n",
    "def fit_svm(X, y, lam, n_iter=1000, eta=.5, tol=1e-10, verbose=0):\n",
    "    nexamples, nfeatures = X.shape\n",
    "    print_size = round(n_iter / 10.)\n",
    "    \n",
    "    w, b = _initialize_parameters(nfeatures)\n",
    "    \n",
    "    for k in range(n_iter):\n",
    "        f = _get_signed_distances(X, w, b)\n",
    "        \n",
    "        # print information and \n",
    "        # update the learning rate\n",
    "        if k % print_size == 0:\n",
    "            obj = _get_objective(f, y, w, lam)\n",
    "            penalty = 0.5 * lam * np.dot(w,w)\n",
    "            loss = obj - penalty\n",
    "            grad_size = np.sum(gw**2) if k > 0 else np.inf\n",
    "            \n",
    "            if verbose > 0:\n",
    "                print(\"it: %d, obj %.2f, loss %.2f, g: %.2f\" % (k, obj, loss, grad_size))\n",
    "                \n",
    "            # check stopping condition\n",
    "            if grad_size < tol:\n",
    "                break\n",
    "                \n",
    "            # update the learning rate\n",
    "            eta = 0.5 * eta\n",
    "        \n",
    "        gw, gb = _get_gradients(f, X, y, w, b, lam)\n",
    "        \n",
    "        # update model parameters\n",
    "        w = w - eta * gw\n",
    "        b = b - eta * gb\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 0, obj 2.02, loss 1.03, g: inf\n",
      "it: 100, obj 17.91, loss 17.44, g: 0.00\n"
     ]
    }
   ],
   "source": [
    "nobs = train_X.shape[0]\n",
    "w,b = fit_svm(train_X, train_y, lam=1.0 , n_iter=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these functions within scikit learn infrastructure so we can tune and compute cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class GDLinearSVM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, lam=1.0, n_iter=1000, eta=.5, tol=1e-10, verbose=0):\n",
    "        self.lam = lam\n",
    "        self.n_iter = n_iter\n",
    "        self.eta = eta\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        self.w_, self.b_ = fit_svm(X, y, lam=self.lam, n_iter=self.n_iter,\n",
    "                                  eta = self.eta, tol=self.tol, verbose=self.verbose)\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        check_is_fitted(self, ['w_', 'b_'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        return _get_signed_distances(X, self.w_, self.b_)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        f = self.decision_function(X)\n",
    "        return np.sign(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# small number of iterations for demonstration purposes\n",
    "gdsvm = GDLinearSVM(n_iter=100)\n",
    "svm_param_grid = [\n",
    "    {'lam': 2 ** np.linspace(-4, 5, num=5)}\n",
    "]\n",
    "\n",
    "gdsvm_tuner = GridSearchCV(gdsvm, svm_param_grid, cv=5, n_jobs=4, verbose=1, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:   44.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GDLinearSVM(eta=0.5, lam=1.0, n_iter=100, tol=1e-10, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid=[{'lam': array([  0.0625 ,   0.2973 ,   1.41421,   6.72717,  32.     ])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdsvm_tuner.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "tuned_gdsvm_auc = cross_val_score(gdsvm_tuner, train_X, train_y,\n",
    "                               scoring='roc_auc', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(tuned_gdsvm_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
